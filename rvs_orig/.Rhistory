X <- X[,t1:t2]
P <- P[t1:t2,]
#  print(RVS_rare1(Y,X,P, nboot=10000))
print(RVS_rare1_zeynep(Y,X,P, nboot=1000))
}
data1=data.frame(X,Y)
data1.split=split(as.data.frame(data1),data1$V1)
cluster.no=length(data1.split)
nX=ncol(X)
for (i in 1:nX) {
for (j in 1:cluster.no) 	{
X.cluster=calc_centralize_matrix(as.data.frame(data1.split[[j]][,i]))
nX.cluster=length(X.cluster)
row.no=sample(1:nX.cluster,nX.cluster,replace=TRUE)
data1.split[[j]][,i]=X.cluster[row.no]
}
}
data2=unsplit(data1.split,data1$V1.1)
X.sampled=data2[,1:nX]
data1=data.frame(X,Y)
data1.split=split(as.data.frame(data1),data1$V1)
cluster.no=length(data1.split)
nX=ncol(X)
for (i in 1:nX) {
for (j in 1:cluster.no) 	{
X.cluster=calc_centralize_matrix(as.data.frame(data1.split[[j]][,i]))
nX.cluster=length(X.cluster)
row.no=sample(1:nX.cluster,nX.cluster,replace=TRUE)
data1.split[[j]][,i]=X.cluster[row.no]
}
}
data2=unsplit(data1.split,data1$V1.1)
View(data1)
data2=unsplit(data1.split,data1$V1.1)
data1.split
data1$V1.1
data1.split
X <- read.csv("C:/Users/Scott/Desktop/RVS-master/example/X.txt", sep="\t", header = F, row.names=NULL)
View(x)
View(x)
View(X)
t(X)
for (i in 1:6){
X <- read.csv("C:/Users/Scott/Desktop/RVS-master/example/X.txt", sep="\t", header = F)
Y <- read.csv("C:/Users/Scott/Desktop/RVS-master/example/Y.txt", sep="\t", header = F)
P <- read.csv("C:/Users/Scott/Desktop/RVS-master/example/P.txt", sep="\t", header = F)
M <- read.csv("C:/Users/Scott/Desktop/RVS-master/example/M.txt", sep="\t", header = T)
njoint=5
t1<-(i-1)*njoint+1;
t2<-i*njoint;
X <- t(X)
X <- X[,t1:t2]
P <- P[t1:t2,]
#  print(RVS_rare1(Y,X,P, nboot=10000))
print(RVS_rare1_zeynep(Y,X,P, nboot=1000))
}
X
#******************************************************************#
#********** REGULAR SCORE TEST FOR RARE VARIANT ANALYSIS ***********#
#*******************************************************************#
calc_ScoreV_zeynep=function (X, Y)
{
L = ncol(X)
S = NULL
for (i in 1:L) {
Yn = Y[!is.na(X[, i]),]
Xn = X[!is.na(X[, i]), i]
s = sum((Yn - mean(Yn)) * Xn)
S = c(S, s)
}
S = t(S)
return(S)
}
calc_ScoreV = function(X,Y){
L = ncol(X)
S = NULL
for (i in 1:L){
Yn = Y[!is.na(X[,i]),]
Xn = X[!is.na(X[,i]),i]
xca = Xn[Yn==1]
xco = Xn[Yn==0]
my = mean(Yn)
s = sum(xca,na.rm=T)*(1-my) - my*sum(xco,na.rm=T)
S = c(S,s)
}
S = t(S)
return (S)
}
calc_ScoreV_regVar_zeynep=function (X, Y)
{
Ym=NULL
for (i in 1:ncol(X)){
Yn = Y[!is.na(X[,i])]
Ym[i] = sqrt( (sum((Yn - mean(Yn))^2)/length(Yn))*length(Y))  #length(Yn))*length(Y) term is like a correction to the different sample sizes in X columns after NAs are removed
}
#  X = check_hom_matrix(X, hom,multiplier)
diag_S = diag(Ym) %*% cov(X,use="pairwise.complete.obs")%*%diag(Ym)
return(diag_S)
}
calc_ScoreV_regVar = function(X,Y){
X1 = X[Y==1,]
X2 = X[Y==0,]
l1 = nrow(X1)
l2 = nrow(X2)
J = ncol(X1)
a =colSums(is.na(X1),na.rm=T)
b =colSums(is.na(X2),na.rm=T)
ncase = rep(l1,J) - a
ncont = rep(l2,J) - b
nn = ncase+ncont
L= length(Y)
Xm = cov(X,use="pairwise.complete.obs")
vs  = sqrt(diag(ncase*ncont/nn^2))
diag_S  = vs%*%Xm%*%vs*L
return (diag_S)
}
#******************************************************************#
#************** RVS TEST FOR RARE VARIANT ANALYSIS ***************#
#*******************************************************************#
sample_bootstrap_zeynep=function(X,Y) {
data1=data.frame(X,Y)
data1.split=split(as.data.frame(data1),data1$V1)
cluster.no=length(data1.split)
nX=ncol(X)
for (i in 1:nX) {
for (j in 1:cluster.no) 	{
X.cluster=calc_centralize_matrix(as.data.frame(data1.split[[j]][,i]))
nX.cluster=length(X.cluster)
row.no=sample(1:nX.cluster,nX.cluster,replace=TRUE)
data1.split[[j]][,i]=X.cluster[row.no]
}
}
data2=unsplit(data1.split,data1$V1)
X.sampled=data2[,1:nX]
return(X.sampled)
}
sample_bootstrap = function(X1,X2){
case = nrow(X1)
cont = nrow(X2)
X1 = calc_centralize_matrix(X1)
X2 = calc_centralize_matrix(X2)
ca = sample(1:case,case,replace=TRUE)
co = sample(1:cont,cont,replace=TRUE)
Xca = as.matrix(X1[ca,])
Xco = as.matrix(X2[co,])
X = rbind(Xca,Xco)
#return (X)
return(list('Xca'=Xca,'Xco'=Xco))
}
#*********************************************************************#
calc_ScoreV_likely_zeynep = function(X,Y,hom,multiplier){
X.lrd = X[Y == 0, ]
X.hrd = X[Y == 1, ]
Y.lrd = Y[Y == 0]
Y.hrd = Y[Y == 1]
X.lrd = check_hom_matrix(X.lrd, hom = hom, multiplier = multiplier)
X.hrd = check_hom_matrix(X.hrd, hom = hom, multiplier = multiplier)
Ym.lrd=Ym.hrd=NULL
for (i in 1:ncol(X)){
Yn = Y[!is.na(X[,i]),]
Yn.lrd = Y.lrd[!is.na(X.lrd[,i])]
Yn.hrd = Y.hrd[!is.na(X.hrd[,i])]
Ym.lrd[i] = sqrt( (sum( (Yn.lrd - mean(Yn))^2)/length(Yn.lrd))*length(Y.lrd))
Ym.hrd[i] = sqrt( (sum((Yn.hrd - mean(Yn))^2)/length(Yn.hrd))*length(Y.hrd))
}
diag_S = diag(Ym.lrd) %*% cov(X.lrd,use="pairwise.complete.obs") %*%diag(Ym.lrd) + diag(Ym.hrd) %*% cov(X.hrd,use="pairwise.complete.obs")%*%diag(Ym.hrd)
return (diag_S)
}
calc_ScoreV_likely = function(X,Y,hom,multiplier,snp_loop){
X1=X[Y==1,]
X2=X[Y==0,]
l1 = nrow(X1)
l2 = nrow(X2)
J = ncol(X1)
a =colSums(is.na(X1),na.rm=T)
b =colSums(is.na(X2),na.rm=T)
ncase = rep(l1,J) - a
ncont = rep(l2,J) - b
nn = ncase+ncont
Yhat = mean(Y)
L= length(Y)
p = l2/l1
q = l1/l2
X1=check_hom_matrix(X1,hom=hom,multiplier=multiplier)
X2=check_hom_matrix(X2,hom=hom,multiplier=multiplier)
Xm1 = cov(X1,use="pairwise.complete.obs")*(l1-1)
Xm2 = cov(X2,use="pairwise.complete.obs")*(l2-1)
vs  = sqrt(diag(ncase*ncont/nn^2))
diag_S  = vs%*%(p*Xm1+ q*Xm2)%*%vs
return (diag_S)
}
#*********************************************************************#
calc_ScoreV_RVS_zeynep = function(X,Y,P,hom,multiplier){
X.lrd = X[Y == 0, ]
X.hrd = X[Y == 1, ]
Y.lrd = Y[Y == 0]
Y.hrd = Y[Y == 1]
L = nrow(P)
V = rep(NA,L)
for (i in 1:L){
V[i] = calc_robust_Var(P[i,])
}
V = diag(sqrt(as.numeric(V)))
X.lrd = check_hom_matrix(X.lrd, hom = hom, multiplier = multiplier)
X.hrd = check_hom_matrix(X.hrd, hom = hom, multiplier = multiplier)
Ym.lrd=Ym.hrd=NULL
for (i in 1:ncol(X)){
Yn = Y[!is.na(X[,i]),]
Yn.lrd = Y.lrd[!is.na(X.lrd[,i])]
Yn.hrd = Y.hrd[!is.na(X.hrd[,i])]
Ym.lrd[i] = sqrt( (sum( (Yn.lrd - mean(Yn))^2)/length(Yn.lrd))*length(Y.lrd))
Ym.hrd[i] = sqrt( (sum((Yn.hrd - mean(Yn))^2)/length(Yn.hrd))*length(Y.hrd))
}
cor.X.hrd = cor.X.function(X.hrd, hom = hom, multiplier = multiplier)
vargroupHRD = t(V) %*% cor.X.hrd %*% V
diag_S = diag(Ym.lrd) %*% cov(X.lrd,use="pairwise.complete.obs") %*%diag(Ym.lrd) + diag(Ym.hrd) %*% vargroupHRD %*%diag(Ym.hrd)
return (diag_S)
}
calc_ScoreV_RVS = function(X,Y,P,hom,multiplier,snp_loop){
X1=X[Y==1,]
X2=X[Y==0,]
L = nrow(P)
V = rep(NA,L)
for (i in 1:L){
V[i] = calc_robust_Var(P[i,])
}
V = diag(sqrt(as.numeric(V)))
l1 = nrow(X1)
l2 = nrow(X2)
Yhat = mean(Y)
L= length(Y)
p = l2/l1
q = l1/l2
#zeynep
X1=check_hom_matrix(X1,hom=hom,multiplier=multiplier)
X2=check_hom_matrix(X2,hom=hom,multiplier=multiplier)
cor.X=cor.X.function(X1,hom=hom,multiplier=multiplier,snp_loop)
Sgcase = t(V)%*%cor.X%*%V*l1
Xm2 = calc_centralize_matrix(X2)
Xm2[is.na(Xm2)]<-0  ## if not set NA to 0, t(Xm2)%*%Xm2 will have too many NAs
## I have checked, t(Xm2)%*%Xm2 is the same as cov(X2) here.
vs  = var(Y)
diag_S  = as.numeric(vs)*(p*Sgcase + q*t(Xm2)%*%Xm2)
return (diag_S)
}
#*********************************************************************#
RVS_rare1= function(Y,X,P,njoint=5,nboot,RVS='TRUE', hom=1,multiplier=1,snp_loop=1){
if(!RVS %in% c('TRUE','True','true','T','t','FALSE','False','false','F','f')) {
cat('Wrong input for option RVS in RVS_rare, should be True or False.\n')
return(NULL)
}
X1 = as.matrix(X[Y==1,])
X2 = as.matrix(X[Y==0,])
S = calc_ScoreV(X,Y)
if(RVS %in% c('TRUE','True','true','T','t')){
Sigma = calc_ScoreV_RVS(X,Y,P,hom,multiplier,snp_loop)  #(*)
}else{
Sigma = calc_ScoreV_likely(X,Y,hom,multiplier,snp_loop) # (*)
}
w = rep(1,ncol(X))
SLobs = test_CAST(S,Sigma,w)
SQobs = test_Calpha(S,Sigma)
Q = NULL
L = NULL
for (i in 1:nboot){
Xs = sample_bootstrap(X1,X2) # (*)
Xa = Xs$Xca  # (*)
Xb = Xs$Xco  # (*)
X = rbind(Xa,Xb)
S = calc_ScoreV(X,Y)
Sigma = calc_ScoreV_likely(X,Y,hom,multiplier)
w = rep(1,ncol(X))
L = c(L,test_CAST(S,Sigma,w))
Q = c(Q,test_Calpha(S,Sigma))
}
pl = (sum(L<=SLobs)+1)/(nboot+1)
pQ = (sum(Q<=SQobs)+1)/(nboot+1)
preturn=c(pl,pQ)
return (preturn)
}
#Changes in "RVS_rare1" : I put (*) beside the lines
# Delete "snp_loop" in functions "calc_ScoreV_RVS" and "calc_ScoreV_likely"
RVS_rare1_zeynep=function(Y,X,P,njoint=5,nboot,RVS='TRUE', hom=1,multiplier=1){
if(!RVS %in% c('TRUE','True','true','T','t','FALSE','False','false','F','f')) {
cat('Wrong input for option RVS in RVS_rare, should be True or False!\n')
return(NULL)
}
S = calc_ScoreV(X,Y)
if(RVS %in% c('TRUE','True','true','T','t')){
Sigma = calc_ScoreV_RVS_zeynep(X,Y,P,hom,multiplier) #(*)
}else{
Sigma = calc_ScoreV_likely_zeynep(X,Y,hom,multiplier)  #(*)
}
w = rep(1,ncol(X))
SLobs = test_CAST(S,Sigma,w)
SQobs = test_Calpha(S,Sigma)
Q = NULL
L = NULL
for (i in 1:nboot){
Xs = sample_bootstrap_zeynep(X,Y)
S = calc_ScoreV(Xs,Y)
Sigma = calc_ScoreV_likely_zeynep(Xs,Y,hom,multiplier)
w = rep(1,ncol(Xs))
L = c(L,test_CAST(S,Sigma,w))
Q = c(Q,test_Calpha(S,Sigma))
}
pl = (sum(L<=SLobs)+1)/(nboot+1)
pQ = (sum(Q<=SQobs)+1)/(nboot+1)
preturn=c(pl,pQ)
#print(mean(L))
return (preturn)
}
for (i in 1:6){
X <- read.csv("C:/Users/Scott/Desktop/RVS-master/example/X.txt", sep="\t", header = F)
Y <- read.csv("C:/Users/Scott/Desktop/RVS-master/example/Y.txt", sep="\t", header = F)
P <- read.csv("C:/Users/Scott/Desktop/RVS-master/example/P.txt", sep="\t", header = F)
M <- read.csv("C:/Users/Scott/Desktop/RVS-master/example/M.txt", sep="\t", header = T)
njoint=5
t1<-(i-1)*njoint+1;
t2<-i*njoint;
X <- t(X)
X <- X[,t1:t2]
P <- P[t1:t2,]
#  print(RVS_rare1(Y,X,P, nboot=10000))
print(RVS_rare1_zeynep(Y,X,P, nboot=1000))
}
for (i in 1:6){
X <- read.csv("C:/Users/Scott/Desktop/RVS-master/example/X.txt", sep="\t", header = F)
Y <- read.csv("C:/Users/Scott/Desktop/RVS-master/example/Y.txt", sep="\t", header = F)
P <- read.csv("C:/Users/Scott/Desktop/RVS-master/example/P.txt", sep="\t", header = F)
M <- read.csv("C:/Users/Scott/Desktop/RVS-master/example/M.txt", sep="\t", header = T)
njoint=5
t1<-(i-1)*njoint+1;
t2<-i*njoint;
X <- t(X)
X <- X[,t1:t2]
P <- P[t1:t2,]
#  print(RVS_rare1(Y,X,P, nboot=10000))
print(RVS_rare1_zeynep(Y,X,P, nboot=1000))
}
#' rbindlist can rbind combine two lists with the same structure.
#'
#' @param list1, the first list,each element is a vector
#' @param list2, the second list,each element is a vector
#' @return a list,  each element is the rbinding of the corresponding element from list1 and list2
#' @export
rbindlist <- function(list1,list2)
{
list3=mapply(rbind,list1,list2,SIMPLIFY=FALSE)
return(list3)
}
N=10000 #Integer. The number of population
preval=0.2 #A decimal between [0,1], prevalence rate of the disease.
nsnp=1000 #Integer. The number of variants or bases.
Ns=2000
ncase=500
ncont=Ns-ncase
nhrd1=200
nhrd2=ncase-nhrd1
nlrd=Ns-nhrd1-nhrd2
rd.group=c(rep(0,nhrd1),rep(1,nhrd2),rep(2,nlrd))
mdhrd1=100
sdhrd1=10
mdhrd2=80
sdhrd2=5
mdlrd=4
sdlrd=1
me=0.01    #The mean error rate of sequencing.
sde=0.025  #The standard deviation for the error rate.
# Generate population data
#We can randomly generate MAF for each SNP
mafco=runif(nsnp,min=0.001,max=0.05) # For common variant choose bigger parameters for uniform.e.g. min=0.1, max=0.5
#or we can determine the minor allele frequency fixed for each collapeed SNPs (5 SNPs in the current setting)
joint=5
loopno=nsnp/njoint
mafco_5=c(0.040856639, 0.021548447, 0.015053696, 0.005911941, 0.022559459)
mafco=rep(mafco_5,loopno)
pop.data=list()
OR=1.  #Under H0
for (i in 1:nsnp) {
pop.data[[i]]=sim.corr.binary.data.pop(N,preval,mafco[i],OR)
cat('lool_snp',i,"\n")
}
save(pop.data,OR,N,preval,nsnp,mafco,file="populationdata.Rdata")
# Call population data (Y and true genotype X), choose sample from the population data with specified sizes, ncase & ncont, and generate the sequencing data and expected genotype to be used in the analysis.
load('populationdata.Rdata')
seqdata.null=generate_seqdata_OR(pop.data,ncase,ncont,rd.group,nhrd1,nhrd2,nlrd,mdhrd1,sdhrd1,mdhrd2,sdhrd2,mdlrd,sdlrd,me,sde,nsnp)
save.image("data_binomial_3groups_underH0.Rdata")
#' rbindlist can rbind combine two lists with the same structure.
#'
#' @param list1, the first list,each element is a vector
#' @param list2, the second list,each element is a vector
#' @return a list,  each element is the rbinding of the corresponding element from list1 and list2
#' @export
rbindlist <- function(list1,list2)
{
list3=mapply(rbind,list1,list2,SIMPLIFY=FALSE)
return(list3)
}
N=10000 #Integer. The number of population
preval=0.2 #A decimal between [0,1], prevalence rate of the disease.
nsnp=1000 #Integer. The number of variants or bases.
Ns=2000
ncase=500
ncont=Ns-ncase
nhrd1=200
nhrd2=ncase-nhrd1
nlrd=Ns-nhrd1-nhrd2
rd.group=c(rep(0,nhrd1),rep(1,nhrd2),rep(2,nlrd))
mdhrd1=100
sdhrd1=10
mdhrd2=80
sdhrd2=5
mdlrd=4
sdlrd=1
me=0.01    #The mean error rate of sequencing.
sde=0.025  #The standard deviation for the error rate.
mafco=runif(nsnp,min=0.001,max=0.05) # For common variant choose bigger parameters for uniform.e.g. min=0.1, max=0.5
joint=5
loopno=nsnp/njoint
mafco_5=c(0.040856639, 0.021548447, 0.015053696, 0.005911941, 0.022559459)
njoint=5
loopno=nsnp/njoint
mafco_5=c(0.040856639, 0.021548447, 0.015053696, 0.005911941, 0.022559459)
mafco_5=c(0.040856639, 0.021548447, 0.015053696, 0.005911941, 0.022559459)
mafco=rep(mafco_5,loopno)
pop.data=list()
OR=1.  #Under H0
for (i in 1:nsnp) {
pop.data[[i]]=sim.corr.binary.data.pop(N,preval,mafco[i],OR)
cat('lool_snp',i,"\n")
}
sim.corr.binary.data.pop=function(N,preval,mafco,OR)
{
Ncont=N-floor(N*preval)
prob.y0<-Ncont/N; prob.y1=1-prob.y0
## p(x=0,y=0)=p(y=0|x=0)*P(x=0)=p(y=0|x=0)*(P(x=0,y=0)+P(x=0,y=1))=(1/(1+exp(beta0)))*(P(x=0,y=0)+p(x=0,y=1))==>p(x=0,y=1)=exp(beta0)*P(x=0,y=0)
## similarly, P(x=1,y=1)=exp(beta0+beta1)*p(x=1,y=0); p(x=2,y=1)=exp(beta0+2beta1)*p(x=2,y=0)
### HWE
## p(x=0,y=0)=P(x=0|y=0)*p(y=0)=(1-mafco)^2*Ncont/N; p(x=1,y=0)=2*(1-mafco)*mafca*Ncont/N; p(x=2,y=0)=mafco^2*Ncont/N, sum(p(x=i,y=0))=p(y=0)=Ncont/N
## p(x=0,y=1)=(1-mafca)^2*Ncase/N; p(x=1,y=1)=2*mafca*(1-mafca)*Ncase/N; p(x=2,y=1)=mafca^2*Ncase/N
### so exp(beta0)*P(x=0,y=0)+exp(beta0+beta1)*p(x=1,y=0)+exp(beta0+2beta1)*p(x=2,y=0)=Ncase/N=1-Ncont/N
## exp(beta0)=(N-Ncont)/(p(x=0,y=0)+exp(beta1)*p(x=1,y=0)+exp(2beta1)*p(x=2,y=0))=(N-Ncont)/(Ncont*(mafca*(1-exp(beta1))-1)^2)
ebeta0=(N-Ncont)/(Ncont*(mafco*(1-OR)-1)^2)
## ebeta0=odds.y1.x0=exp(beta0); OR=ebeta1:=exp(beta1)
odds.y1.x0<-ebeta0;
odds.y1.x1<-ebeta0*OR
odds.y1.x2<- ebeta0*OR^2
#  cat('ebeta0=',ebeta0,'\n')
Ncase=N-Ncont
## p(x=0,y=0), p(x=1,y=0), p(x=0,y=1), p(x=1,y=1)
prob.x0.y0=Ncont/N*(1-mafco)^2; prob.x1.y0=2*mafco*(1-mafco)*Ncont/N;
prob.x0.y1=odds.y1.x0*prob.x0.y0; prob.x1.y1=odds.y1.x0*OR*prob.x1.y0
Y=c(rep(1,Ncase),rep(0,Ncont))
tmp=runif(Ncase,min=0,max=prob.y1)  ## prob(x=0,y=1)+prob(x=1,y=1)+prob(x=2,y=1)=prob(y=1)
x1<-ifelse(tmp>prob.x0.y1,ifelse(tmp<prob.x0.y1+prob.x1.y1,1,2),0)
tmp=runif(Ncont,min=0,max=prob.y0)  #prob(x=0,y=0)+prob(x=1,y=0)+prob(x=2,y=0)=prob(y=0)
x0<-ifelse(tmp>prob.x0.y0,ifelse(tmp<prob.x0.y0+prob.x1.y0,1,2),0)
x=c(x1,x0)
dat<-data.frame(x=x,y=Y)
return(dat)
}
for (i in 1:nsnp) {
pop.data[[i]]=sim.corr.binary.data.pop(N,preval,mafco[i],OR)
cat('lool_snp',i,"\n")
}
pop.data
pop.data[[1]]
mafco
cat
cat?
?cat
seqdata.null = list()
#' rbindlist can rbind combine two lists with the same structure.
#'
#' @param list1, the first list,each element is a vector
#' @param list2, the second list,each element is a vector
#' @return a list,  each element is the rbinding of the corresponding element from list1 and list2
#' @export
rbindlist <- function(list1,list2)
{
list3=mapply(rbind,list1,list2,SIMPLIFY=FALSE)
return(list3)
}
choose.sample
sample
?sample
xxx = c(1,2,3,4,5,6,7,8,9,10)
sample(xxx)
sample(xxx, 2)
sample(xxx, 2)
sample(xxx, 2)
sample(xxx, 2)
sample(xxx, 2)
sample(xxx)
sample(xxx, 2)
sample(xxx, 2)
sample(xxx, 2)
sample(xxx, 2)
sample(xxx, 2)
sample(xxx, 2)
sample(xxx, 2)
sample(xxx)
sample(xxx)
sample(xxx)
sample(xxx)
sample(xxx)
sample(xxx)
sample(xxx, 9)
sample(xxx, 9)
sample(xxx, 9)
sample(xxx, 9)
